{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup and Processing\n",
    "\n",
    "This notebook handles:\n",
    "1. Decompressing GZ files to JSON\n",
    "2. Converting JSON files to Parquet in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import duckdb\n",
    "import os\n",
    "import gzip\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs('/data/json', exist_ok=True)\n",
    "os.makedirs('/data/parquet', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Decompress GZ Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def decompress_gz_files():\n",
    "    gz_files = glob.glob('/data/elasticsearch/*.json.gz')\n",
    "    \n",
    "    for gz_file in gz_files:\n",
    "        base_name = os.path.basename(gz_file)\n",
    "        json_name = base_name[:-3]  # Remove .gz extension\n",
    "        json_path = os.path.join('/data/json', json_name)\n",
    "        \n",
    "        print(f\"ðŸ”„ Decompressing {base_name}...\")\n",
    "        \n",
    "        with gzip.open(gz_file, 'rb') as f_in:\n",
    "            with open(json_path, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "                \n",
    "        print(f\"âœ… Created {json_name}\")\n",
    "\n",
    "decompress_gz_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert JSON to Parquet in Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def convert_to_parquet(json_file):\n",
    "    print(f\"\\nðŸ”„ Processing {os.path.basename(json_file)}\")\n",
    "    \n",
    "    # Connect to DuckDB\n",
    "    con = duckdb.connect()\n",
    "    \n",
    "    # Count total rows\n",
    "    total_rows = con.execute(f\"SELECT COUNT(*) FROM read_ndjson_objects('{json_file}');\").fetchone()[0]\n",
    "    chunk_size = total_rows // 10\n",
    "    print(f\"ðŸ“Š Total rows: {total_rows} | Chunk size: {chunk_size}\")\n",
    "    \n",
    "    # Process in 10 chunks\n",
    "    offset = 0\n",
    "    base_name = os.path.basename(json_file)\n",
    "    file_name = os.path.splitext(base_name)[0]\n",
    "    \n",
    "    for i in range(10):\n",
    "        print(f\"ðŸ”„ Processing chunk {i+1}/10 (Offset: {offset})...\")\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        CREATE OR REPLACE TABLE batch_data AS\n",
    "        SELECT * FROM read_ndjson_objects('{json_file}')\n",
    "        LIMIT {chunk_size} OFFSET {offset};\n",
    "        \"\"\"\n",
    "        con.execute(query)\n",
    "        \n",
    "        count = con.execute(\"SELECT COUNT(*) FROM batch_data;\").fetchone()[0]\n",
    "        if count == 0:\n",
    "            print(\"âœ… No more rows to process.\")\n",
    "            break\n",
    "        \n",
    "        # Save chunk as Parquet\n",
    "        parquet_file = f\"/data/parquet/{file_name}_{i+1}.parquet\"\n",
    "        con.execute(f\"COPY batch_data TO '{parquet_file}' (FORMAT 'parquet', COMPRESSION 'zstd');\")\n",
    "        print(f\"âœ… Saved: {os.path.basename(parquet_file)} ({count} rows)\")\n",
    "        \n",
    "        offset += count\n",
    "    \n",
    "    con.close()\n",
    "    print(f\"âœ… Completed processing {base_name}\")\n",
    "\n",
    "# Process all JSON files\n",
    "json_files = glob.glob('/data/json/*.json')\n",
    "for json_file in json_files:\n",
    "    convert_to_parquet(json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
